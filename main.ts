"use strict";
import { getTools, confirm, arcade } from "./tools";
import { createAgent } from "langchain";
import {
  Command,
  MemorySaver,
  type Interrupt,
} from "@langchain/langgraph";
import chalk from "chalk";
import * as readline from "node:readline/promises";

// configure your own values to customize your agent

// The Arcade User ID identifies who is authorizing each service.
const arcadeUserID = process.env.ARCADE_USER_ID;
if (!arcadeUserID) {
  throw new Error("Missing ARCADE_USER_ID. Add it to your .env file.");
}
// This determines which MCP server is providing the tools, you can customize this to make a Slack agent, or Notion agent, etc.
// all tools from each of these MCP servers will be retrieved from arcade
const toolkits=['Linkedin'];
// This determines isolated tools that will be
const isolatedTools=[];
// This determines the maximum number of tool definitions Arcade will return
const toolLimit = 100;
// This prompt defines the behavior of the agent.
const systemPrompt = "# AI Agent Prompt for LinkedIn Post Creation\n\n## Introduction\nThis AI agent is designed to assist users in crafting and sharing engaging text posts on LinkedIn. By understanding user inputs and utilizing the available tools, the agent will create and publish timely and relevant content tailored for a professional network.\n\n## Instructions\n1. **Understand User Intent**: Begin by asking the user what topic or message they would like to share on LinkedIn.\n2. **Gather Input**: After clarifying the topic, collect any additional details, such as tone, targeted audience, and any specific key points the user wishes to include.\n3. **Compose the Post**: Create a compelling text post based on the gathered information. Ensure it aligns with professional standards and resonates with a LinkedIn audience.\n4. **Publish the Post**: Utilize the `Linkedin_CreateTextPost` tool to share the composed text post on LinkedIn.\n\n## Workflows\n### Workflow 1: Topic and Message Collection\n1. **User Input**: Ask the user what topic they want to share.\n2. **Clarification**: Request further details regarding tone, audience, and key points.\n\n### Workflow 2: Post Composition\n1. **Create Text**: Based on user input, write a draft for the LinkedIn post.\n\n### Workflow 3: Posting to LinkedIn\n1. **Use Tool**: Execute the `Linkedin_CreateTextPost` tool with the composed text to share it on LinkedIn.\n\nBy following these workflows, the agent will facilitate a smooth experience for users looking to engage with their professional network on LinkedIn.";
// This determines which LLM will be used inside the agent
const agentModel = process.env.OPENAI_MODEL;
if (!agentModel) {
  throw new Error("Missing OPENAI_MODEL. Add it to your .env file.");
}
// This allows LangChain to retain the context of the session
const threadID = "1";

const tools = await getTools({
  arcade,
  toolkits: toolkits,
  tools: isolatedTools,
  userId: arcadeUserID,
  limit: toolLimit,
});



async function handleInterrupt(
  interrupt: Interrupt,
  rl: readline.Interface
): Promise<{ authorized: boolean }> {
  const value = interrupt.value;
  const authorization_required = value.authorization_required;
  const hitl_required = value.hitl_required;
  if (authorization_required) {
    const tool_name = value.tool_name;
    const authorization_response = value.authorization_response;
    console.log("‚öôÔ∏è: Authorization required for tool call", tool_name);
    console.log(
      "‚öôÔ∏è: Please authorize in your browser",
      authorization_response.url
    );
    console.log("‚öôÔ∏è: Waiting for you to complete authorization...");
    try {
      await arcade.auth.waitForCompletion(authorization_response.id);
      console.log("‚öôÔ∏è: Authorization granted. Resuming execution...");
      return { authorized: true };
    } catch (error) {
      console.error("‚öôÔ∏è: Error waiting for authorization to complete:", error);
      return { authorized: false };
    }
  } else if (hitl_required) {
    console.log("‚öôÔ∏è: Human in the loop required for tool call", value.tool_name);
    console.log("‚öôÔ∏è: Please approve the tool call", value.input);
    const approved = await confirm("Do you approve this tool call?", rl);
    return { authorized: approved };
  }
  return { authorized: false };
}

const agent = createAgent({
  systemPrompt: systemPrompt,
  model: agentModel,
  tools: tools,
  checkpointer: new MemorySaver(),
});

async function streamAgent(
  agent: any,
  input: any,
  config: any
): Promise<Interrupt[]> {
  const stream = await agent.stream(input, {
    ...config,
    streamMode: "updates",
  });
  const interrupts: Interrupt[] = [];

  for await (const chunk of stream) {
    if (chunk.__interrupt__) {
      interrupts.push(...(chunk.__interrupt__ as Interrupt[]));
      continue;
    }
    for (const update of Object.values(chunk)) {
      for (const msg of (update as any)?.messages ?? []) {
        console.log("ü§ñ: ", msg.toFormattedString());
      }
    }
  }

  return interrupts;
}

async function main() {
  const config = { configurable: { thread_id: threadID } };
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  console.log(chalk.green("Welcome to the chatbot! Type 'exit' to quit."));
  while (true) {
    const input = await rl.question("> ");
    if (input.toLowerCase() === "exit") {
      break;
    }
    rl.pause();

    try {
      let agentInput: any = {
        messages: [{ role: "user", content: input }],
      };

      // Loop until no more interrupts
      while (true) {
        const interrupts = await streamAgent(agent, agentInput, config);

        if (interrupts.length === 0) {
          break; // No more interrupts, we're done
        }

        // Handle all interrupts
        const decisions: any[] = [];
        for (const interrupt of interrupts) {
          decisions.push(await handleInterrupt(interrupt, rl));
        }

        // Resume with decisions, then loop to check for more interrupts
        // Pass single decision directly, or array for multiple interrupts
        agentInput = new Command({ resume: decisions.length === 1 ? decisions[0] : decisions });
      }
    } catch (error) {
      console.error(error);
    }

    rl.resume();
  }
  console.log(chalk.red("üëã Bye..."));
  process.exit(0);
}

// Run the main function
main().catch((err) => console.error(err));